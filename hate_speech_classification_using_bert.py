# -*- coding: utf-8 -*-
"""Hate_Speech_Classification_using_BERT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WgWfk_DgwyCq9sl_MTXz8fFqaBEAJvIZ
"""

# Install or upgrade the 'datasets' library
!pip install -U datasets

import polars as pl
import pandas
from datasets import Dataset

# Load the dataset from a parquet file hosted on the Hugging Face Hub using polars
df = pl.read_parquet('hf://datasets/Intuit-GenSRF/hate-speech18-es/data/train-00000-of-00001-3075deaca2ec2f5b.parquet')

# Convert the polars DataFrame to a pandas DataFrame
df = df.to_pandas()

# Convert the pandas DataFrame to a Hugging Face Dataset object
hate = Dataset.from_pandas(df)

# Print the column names of the dataset
print(hate.column_names)

# Print the total number of examples in the dataset
print(len(hate))

# Print the first example in the dataset
print(hate[0])

import random
from datasets import concatenate_datasets

# Shuffle the original dataset and select the first 500 examples to create a smaller subset
small_hate = hate.shuffle(seed=42).select(range(500))

# Define a function to convert the 'labels' column (list of strings) to a binary label (0 or 1)
# If the 'labels' list is not empty, the label is 1 (hate speech), otherwise it's 0 (not hate speech)
def to_binary(example):
    return {"text": example["text"], "label": 1 if example["labels"] else 0}

# Apply the to_binary function to the small_hate dataset to create a new dataset with binary labels
# Remove the original columns except 'text' and the new 'label' column
binary_hate = small_hate.map(to_binary, remove_columns=[c for c in small_hate.column_names if c not in ("text","label")])

# Get the indices of examples with label 1 (hate speech)
idx_pos = [i for i, ex in enumerate(binary_hate) if ex["label"] == 1]

# Get the indices of examples with label 0 (not hate speech)
idx_neg = [i for i, ex in enumerate(binary_hate) if ex["label"] == 0]

# Define a function to sample indices from a list, with replacement if the list is smaller than the desired sample size
def sample_indices(idxs, n):
    if len(idxs) >= n:
        return random.sample(idxs, n)
    else:
        return [random.choice(idxs) for _ in range(n)]

# Sample 500 indices from the positive examples (with replacement if less than 100 positive examples)
sampled_pos = sample_indices(idx_pos, 100)

# Sample 500 indices from the negative examples (with replacement if less than 100 negative examples)
sampled_neg = sample_indices(idx_neg, 100)

# Select the examples corresponding to the sampled indices for both positive and negative classes
ds_pos = binary_hate.select(sampled_pos)
ds_neg = binary_hate.select(sampled_neg)

# Concatenate the positive and negative datasets and shuffle them to create a balanced dataset
balanced = concatenate_datasets([ds_pos, ds_neg]).shuffle(seed=42)

# Import Counter from collections to count the occurrences of each label
from collections import Counter

# Print the distribution of labels in the balanced dataset
print(Counter(balanced["label"]))

from collections import Counter
import matplotlib.pyplot as plt

# Count the occurrences of each label in the balanced dataset
label_counts = Counter(balanced["label"])

# Print the label distribution
print("Label distribution in the balanced dataset:", label_counts)

# Create a bar plot to visualize the label distribution
plt.bar(label_counts.keys(), label_counts.values())

# Set the x-axis tick labels to be more descriptive
plt.xticks([0, 1], ['Not Hate Speech (0)', 'Hate Speech (1)'])

# Set the x-axis label
plt.xlabel("Label")

# Set the y-axis label
plt.ylabel("Count")

# Set the title of the plot
plt.title("Distribution of Labels in Balanced Dataset")

# Display the plot
plt.show()

from transformers import AutoTokenizer
from torch.utils.data import DataLoader

# Load the tokenizer for the 'bert-base-uncased' model
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Define a function to tokenize a batch of text examples
def tokenize_batch(batch):
    return tokenizer(
        batch["text"],       # Input text to tokenize
        padding="max_length", # Pad sequences to the maximum length
        truncation=True,      # Truncate sequences longer than max_length
        max_length=128        # Set the maximum sequence length
    )

# Apply the tokenization function to the balanced dataset
tokenized = balanced.map(tokenize_batch, batched=True)

# Set the format of the dataset to PyTorch tensors for specific columns
tokenized.set_format("torch", columns=["input_ids", "attention_mask", "label"])

# Create a DataLoader for the tokenized dataset for training
# Batch size is 16, and data is shuffled
train_loader = DataLoader(tokenized, batch_size=16, shuffle=True)

# Get the first batch from the DataLoader
batch = next(iter(train_loader))

# Print the shapes of the tensors in the batch
print({k: v.shape for k, v in batch.items()})

import matplotlib.pyplot as plt

# Calculate the length of each text example in tokens using the tokenizer
text_lengths = [len(tokenizer.encode(example["text"])) for example in balanced]

# Create a histogram to visualize the distribution of text lengths
plt.hist(text_lengths, bins=50)

# Set the x-axis label
plt.xlabel("Text Length (tokens)")

# Set the y-axis label
plt.ylabel("Frequency")

# Set the title of the plot
plt.title("Distribution of Text Lengths")

# Display the plot
plt.show()

from collections import Counter
import nltk
from nltk.corpus import stopwords
import pandas as pd

# Download the stopwords corpus from NLTK
nltk.download('stopwords')

# Get the set of English stop words
stop_words = set(stopwords.words('english'))

# Define a function to get the most common words for a given label in the dataset
def get_most_common_words(dataset, label, num_words=20):
    # Join all text examples for the given label into a single string
    text_for_label = " ".join([example["text"] for example in dataset if example["label"] == label])

    # Convert the text to lowercase and split it into words
    words = text_for_label.lower().split()

    # Filter out non-alphabetic words and stop words
    words = [word for word in words if word.isalpha() and word not in stop_words]

    # Count the frequency of each word
    word_counts = Counter(words)

    # Return the most common words and their counts
    return word_counts.most_common(num_words)

# Get the most common words for the 'Not Hate Speech' label (0)
common_words_neg = get_most_common_words(balanced, 0)

# Get the most common words for the 'Hate Speech' label (1)
common_words_pos = get_most_common_words(balanced, 1)

# Print the most common words for the 'Not Hate Speech' label
print("Most common words in 'Not Hate Speech' (Label 0):")
for word, count in common_words_neg:
    print(f"{word}: {count}")

# Print the most common words for the 'Hate Speech' label
print("\nMost common words in 'Hate Speech' (Label 1):")
for word, count in common_words_pos:
    print(f"{word}: {count}")

import matplotlib.pyplot as plt
import pandas as pd

# Create a pandas DataFrame from the common words and counts for the negative class
df_neg = pd.DataFrame(common_words_neg, columns=['word', 'count'])

# Create a pandas DataFrame from the common words and counts for the positive class
df_pos = pd.DataFrame(common_words_pos, columns=['word', 'count'])

# Create a figure and axes for the first plot (Not Hate Speech)
plt.figure(figsize=(10, 6))

# Create a bar plot of the most common words for the negative class
plt.bar(df_neg['word'], df_neg['count'])

# Rotate the x-axis labels for better readability
plt.xticks(rotation=45, ha='right')

# Set the x-axis label
plt.xlabel("Word")

# Set the y-axis label
plt.ylabel("Frequency")

# Set the title of the plot
plt.title("Most Common Words in 'Not Hate Speech'")

# Adjust layout to prevent labels from overlapping
plt.tight_layout()

# Display the plot
plt.show()

# Create a figure and axes for the second plot (Hate Speech)
plt.figure(figsize=(10, 6))

# Create a bar plot of the most common words for the positive class with orange color
plt.bar(df_pos['word'], df_pos['count'], color='orange')

# Rotate the x-axis labels for better readability
plt.xticks(rotation=45, ha='right')

# Set the x-axis label
plt.xlabel("Word")

# Set the y-axis label
plt.ylabel("Frequency")

# Set the title of the plot
plt.title("Most Common Words in 'Hate Speech'")

# Adjust layout to prevent labels from overlapping
plt.tight_layout()

# Display the plot
plt.show()

from transformers import (
    AutoModelForSequenceClassification,
    Trainer,
    TrainingArguments,
)
import numpy as np
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

# Load the pre-trained BERT model for sequence classification
# Specify the number of labels (2 for binary classification)
model = AutoModelForSequenceClassification.from_pretrained(
    "bert-base-uncased",
    num_labels=2
)

# Define a function to compute evaluation metrics
def compute_metrics(eval_pred):
    # Get logits and true labels from the evaluation predictions
    logits, labels = eval_pred

    # Get the predicted class by finding the index of the maximum logit
    preds = np.argmax(logits, axis=-1)

    # Calculate and return accuracy, F1 score, precision, and recall
    return {
        "accuracy": accuracy_score(labels, preds),
        "f1": f1_score(labels, preds, average="binary"), # Use binary average for binary classification
        "precision": precision_score(labels, preds),
        "recall": recall_score(labels, preds),
    }

# Define the training arguments for the Trainer
training_args = TrainingArguments(
    output_dir="./results",              # Directory to save the model checkpoints and outputs
    num_train_epochs=3,                 # Total number of training epochs
    per_device_train_batch_size=16,      # Batch size per device during training
    per_device_eval_batch_size=32,       # Batch size per device during evaluation
    warmup_steps=50,                     # Number of steps for the warmup phase of the learning rate scheduler
    weight_decay=0.01,                   # Strength of weight decay
    logging_steps=10,                    # Log training information every 10 steps
    eval_strategy="steps",               # Evaluate the model every `logging_steps`
    eval_steps=50,                       # Evaluate the model every `evaluation steps`
    load_best_model_at_end=True,         # Load the best model checkpoint at the end of training
    metric_for_best_model="f1",          # Metric to use to determine the best model
    report_to="none",                    # Do not report training progress to any external service
)

# Initialize the Trainer with the model, training arguments, datasets, and compute_metrics function
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized, # Use the tokenized dataset for training
    eval_dataset=tokenized,  # Use the tokenized dataset for evaluation (can be a separate validation set)
    compute_metrics=compute_metrics,
)

# Start the training process
trainer.train()

# Evaluate the trained model on the evaluation dataset
trainer.evaluate()

import numpy as np

# Make predictions on the tokenized dataset using the trained model
predictions = trainer.predict(tokenized)

# Extract the true labels from the predictions object
true_labels = predictions.label_ids

# Get the predicted labels by finding the index of the maximum logit for each prediction
predicted_labels = np.argmax(predictions.predictions, axis=-1)

from sklearn.metrics import confusion_matrix

# Compute the confusion matrix using the true and predicted labels
cm = confusion_matrix(true_labels, predicted_labels)

import seaborn as sns
import matplotlib.pyplot as plt

# Create a figure for the heatmap
plt.figure(figsize=(8, 6))

# Create a heatmap of the confusion matrix
# annot=True displays the values in the cells
# fmt="d" formats the annotations as integers
# cmap="Blues" sets the color map to blues
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")

# Set the x-axis label
plt.xlabel("Predicted Label")

# Set the y-axis label
plt.ylabel("True Label")

# Set the title of the plot
plt.title("Confusion Matrix")

# Display the plot
plt.show()

import torch

# Shuffle the original dataset and select the text from the first 3 examples
sample_texts = hate.shuffle(seed=42).select(range(3))['text']

# Define a dictionary to map class indices to human-readable labels
label_map = {0: "Not Hate Speech", 1: "Hate Speech"}

# Determine the device to use for inference (GPU if available, otherwise CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Move the model to the selected device
model.to(device)

# Iterate through the sample texts
for sample_text in sample_texts:
    # Tokenize the sample text and convert it to PyTorch tensors
    # Add padding and truncation to match the model's input requirements
    inputs = tokenizer(sample_text, return_tensors="pt", padding="max_length", truncation=True, max_length=128)

    # Move the input tensors to the selected device
    inputs = {k: v.to(device) for k, v in inputs.items()}

    # Perform inference without calculating gradients
    with torch.no_grad():
        # Pass the inputs through the model to get the outputs (logits)
        outputs = model(**inputs)

    # Get the predicted class by finding the index with the highest logit
    predicted_class = torch.argmax(outputs.logits, dim=1).item()

    # Get the human-readable label for the predicted class
    predicted_label = label_map[predicted_class]

    # Print the sample text, predicted class, and predicted label
    print(f"Sample Text: '{sample_text}'")
    print(f"Predicted Class: {predicted_class}")
    print(f"Predicted Label: {predicted_label}\n")

